{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n\nimport warnings \nwarnings.filterwarnings(\"ignore\")\nimport os\nfrom os.path import join\nimport time\nfrom tqdm import tqdm\n\nimport numpy as np\nfrom numpy.random import choice\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import cohen_kappa_score\n\nimport PIL\nfrom PIL import Image\nimport cv2\n\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models as md\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-29T15:35:47.308133Z","iopub.execute_input":"2021-10-29T15:35:47.308572Z","iopub.status.idle":"2021-10-29T15:35:49.876588Z","shell.execute_reply.started":"2021-10-29T15:35:47.308383Z","shell.execute_reply":"2021-10-29T15:35:49.875629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data pre-processing","metadata":{}},{"cell_type":"code","source":"DATA_DIR = '../input/aptos2019-blindness-detection'\n\ntrain_dir = join(DATA_DIR, 'train_images')\nlabel_df  = pd.read_csv(join(DATA_DIR, 'train.csv'))\n\n\ndef train_validation_split(df, val_fraction=0.1):\n    val_ids  = np.random.choice(df.id_code, size=int(len(df) * val_fraction))\n    val_df   = df.query('id_code     in @val_ids')\n    train_df = df.query('id_code not in @val_ids')\n    return train_df, val_df\n\n\ntrain_df, val_df = train_validation_split(label_df)\nprint(train_df.shape, val_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T15:36:58.276543Z","iopub.execute_input":"2021-10-29T15:36:58.276875Z","iopub.status.idle":"2021-10-29T15:36:58.335776Z","shell.execute_reply.started":"2021-10-29T15:36:58.276819Z","shell.execute_reply":"2021-10-29T15:36:58.335028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crop_image_from_gray(img,tol=7):\n    \"\"\"\n    This function from:\n    https://www.kaggle.com/ratthachat/aptos-updatedv14-preprocessing-ben-s-cropping\n    \"\"\"\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n\n\ncv_to_pil = transforms.ToPILImage()\n\n    \ndef center_crop(image: PIL.Image):\n    \"\"\"\n    Only gets center square (of rectangular images) - no resizing\n    => diffently sized square images\n    \"\"\"\n    old_width, old_heigh = image.size\n    new_size = min(old_width, old_heigh)\n    \n    margin_x = (old_width - new_size) // 2\n    margin_y = (old_heigh - new_size) // 2\n    \n    left   = margin_x\n    right  = margin_x + new_size\n    top    = margin_y\n    bottom = margin_y + new_size\n    \n    return image.crop( (left, top, right, bottom) )\n\n\ndef process_image_ratio_invariant(cv2_image, size=256, do_center_crop=True):\n    \n    image = cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    #image = cv2.resize(image, (size, size))  # this would distort eyeball shape\n    \n    if do_center_crop is False:\n        return image\n    \n    # crop the largest possible square from the center\n    pil_img = cv_to_pil(image)\n    pil_img = center_crop(pil_img)\n    image   = np.array(pil_img).copy()\n    \n    # now we have quadratic, but differently sized images\n    # => resize without altering the shape of the eyeball\n    image = cv2.resize(image, (size, size))\n    \n    # add gaussian blur with sigma proportional to new size:\n    image = cv2.addWeighted (image, 4, cv2.GaussianBlur(image, (0, 0) , size/30) , -4 ,128)\n        \n    return cv_to_pil(image)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T15:37:29.674787Z","iopub.execute_input":"2021-10-29T15:37:29.675081Z","iopub.status.idle":"2021-10-29T15:37:29.691923Z","shell.execute_reply.started":"2021-10-29T15:37:29.675033Z","shell.execute_reply":"2021-10-29T15:37:29.690826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n    \nclass Diabetic_Retionopathy_Data(Dataset):\n    \n    def __init__(self,\n                 image_dir: str,\n                 label_df: pd.DataFrame,\n                 train=True,\n                 transform=transforms.ToTensor(),\n                 sample_n=None,\n                 in_memory=False,\n                 write_images=False):\n        \"\"\"\n        @ image_dir:   path to directory with images\n        @ label_df:    df with image id (str) and label (0/1) - only for labeled test-set\n        @ transforms:  image transformation; by default no transformation\n        @ sample_n:    if not None, only use that many observations\n        \"\"\"\n        self.image_dir = image_dir\n        self.transform = transform\n        self.train     = train\n        self.in_memory = in_memory\n        \n        if sample_n:\n            label_df  = label_df.sample(n=min(sample_n, len(label_df)))\n            \n        ids            = set(label_df.id_code)\n        self.img_files = [f for f in os.listdir(image_dir) if f.split('.')[0] in ids]\n        label_df.index = label_df.id_code\n        self.label_df  = label_df.drop('id_code', axis=1)\n        \n        if in_memory:\n            \n            self.id2image = {}\n            for i, file_name in enumerate(self.img_files):\n                \n                if i and i % 500 == 0:\n                    print(f'{i} / {len(self.img_files)}')\n                \n                image = self._read_process_image(join(image_dir, file_name))\n                id_   = file_name.split('.')[0]\n                self.id2image[id_] = image\n                \n                if write_images:\n                    image.save(file_name)\n                    \n        print(f'Initialized datatset with {len(self.img_files)} images.\\n')\n        \n    @staticmethod\n    def _read_process_image(file_path: str, size=256):\n        image = cv2.imread(file_path)        \n        return process_image_ratio_invariant(image, size=size)        \n\n    def __getitem__(self, idx):\n\n        file_name = self.img_files[idx]\n        id_ = file_name.split('.')[0]\n        \n        if self.in_memory:\n            img = self.id2image[id_]\n        else:\n            img = self._read_process_image(join(self.image_dir, file_name))\n        \n        X   = self.transform(img)\n        \n        if self.train:\n            y = float(self.label_df.loc[id_].diagnosis)\n            return X, y, id_\n        else:\n            return X, id_\n    \n    def __len__(self):\n        return len(self.img_files)\n\n\nclass RandomCenterCrop(transforms.CenterCrop):\n    \"\"\"\n    Crops the PIL Image at the center.\n    :param: min_size, max_size: range of crop-size randomly within [min_size, max_size]\n    \"\"\"\n    def __init__(self, min_size: int, max_size: int):\n        self.min_size = min_size\n        self.max_size = max_size\n        \n    def __call__(self, img):\n        \"\"\"\n        Args:\n            img (PIL Image): Image to be cropped.\n        Returns:\n            PIL Image: Cropped image.\n        \"\"\"\n        size = np.random.randint(self.min_size, self.max_size + 1)\n        crop = transforms.CenterCrop( (size, size) )\n        return crop(img)\n\n    def __repr__(self):\n        return f'{self.__class__.__name__}: (min-size={self.min_size}, max-size={self.max_size})'\n\n\nbatchsize = 3\n\n# due to the large amount of data, random transformations might not be necessary...\ntrain_transform = transforms.Compose([\n    RandomCenterCrop(min_size=200, max_size=256),\n    transforms.Resize( (256, 256) ),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation( (-20, 20) ),  \n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntrain = Diabetic_Retionopathy_Data(train_dir,\n                                   train_df,\n                                   transform=train_transform,\n                                   in_memory=True,\n                                   write_images=False)\nval   = Diabetic_Retionopathy_Data(train_dir,\n                                   val_df,\n                                   transform=train_transform,\n                                   in_memory=True,\n                                   write_images=False)\n\ntrain_loader = DataLoader(train, batch_size=batchsize, num_workers=4, shuffle=True)\nval_loader   = DataLoader(val,   batch_size=batchsize, num_workers=3, shuffle=False)\n\nX, y, _ = next(iter(val_loader))\nprint(f'batch-dimension:\\nX = {X.shape},\\ny = {y.shape}')\nprint(f'number of batches:\\ntrain: {len(train_loader)}\\nvalidation: {len(val_loader)}')","metadata":{"execution":{"iopub.status.busy":"2021-10-29T15:47:24.399463Z","iopub.execute_input":"2021-10-29T15:47:24.400362Z","iopub.status.idle":"2021-10-29T15:58:22.422896Z","shell.execute_reply.started":"2021-10-29T15:47:24.400233Z","shell.execute_reply":"2021-10-29T15:58:22.422141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check pre-processing: compare raw vs. pre-processed images","metadata":{}},{"cell_type":"code","source":"def show_processed_images(image_dir, n=5, label_df=None, tf=None):\n    \n    sample_files = np.random.choice(os.listdir(image_dir), size=n)\n    \n    for file_name in sample_files:\n        \n        if label_df is not None:\n            id_ = file_name.split('.')[0]\n            diagnosis = label_df.query('id_code == @id_').diagnosis.item()\n        else:\n            diagnosis = 'unknown'\n        \n        image     = cv2.imread(join(image_dir, file_name))\n        raw_image = cv_to_pil(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n        \n        if tf is not None:\n            processed_image = tf(join(image_dir, file_name))\n        \n        fig, (ax1, ax2) = plt.subplots(1, 2)\n        fig.set_size_inches(10, 5)\n        \n        ax1.imshow(raw_image)\n        if tf is not None:\n            ax2.imshow(processed_image)\n        ax1.set_title('raw')\n        ax2.set_title('processed')\n        \n        fig.suptitle(f'diagnosis = {diagnosis}')            \n        plt.show()\n        \n    \nprint('TRAINING DATA:')\nshow_processed_images(join(DATA_DIR, 'train_images'),\n                      label_df=pd.concat([train_df, val_df]),\n                      tf=train._read_process_image)\nprint('TEST DATA:')\nshow_processed_images(join(DATA_DIR, 'test_images'),\n                      tf=train._read_process_image)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T16:16:22.739648Z","iopub.execute_input":"2021-10-29T16:16:22.741576Z","iopub.status.idle":"2021-10-29T16:16:29.547595Z","shell.execute_reply.started":"2021-10-29T16:16:22.741225Z","shell.execute_reply":"2021-10-29T16:16:29.546903Z"},"trusted":true},"execution_count":null,"outputs":[]}]}